
 철수와 맹구를 학습시켜 비교하엿다
 안철수를 넣었더니 철수가 아닌 맹구가 나온 의외의 결과가 도출되었다.
![스크린샷(5)](https://github.com/sejongsmarcle/2024_Spring_SMARCLE_Snaegi_Study/assets/70049326/e7c55339-95aa-472d-bedc-0559f8ede3f5)

epoch: 사전적 의미: (중요한 사건·변화들이 일어난) 시대
딥러닝에서 epoch는 전체 데이터 셋이 신경망을 통과한 횟수 의미함, 즉 모든 데이터셋을 학습 하는 횟수를 의미한다.
예로, 1-epoch은 전체 데이터셋이 하나의 신경망에 적용되어 순전파와 역전파를 통해 신경망을 한 번 통과했다는 것을 의미한다.
문제집에 있는 모든 문제들을 풀고 채점까지 맞췄다는 것.
(문제집 한 권 전체를 1번 푼 사람이 있듯이, 2번, 3번 5번 푼 사람도 존재한다. Epoch은 따라서, 문제집 한 권 전체를 몇 회 풀었는지를 의미하는 것)


batch size: 사전적 의미: (일괄적으로 처리되는) 집단, 무리
전체 데이터 셋을 여러 작은 그룹을 나누었을 때 batch size는 하나의 소그룹에 속하는 데이터 수를 의미한다.
1000개의 수학문제를 20개씩 나눠서 푸는 것으로 생각하면 된다. ( 여기서 20이 batch size)
(문제를 다 푼 후 사람이 채점하고 틀린 문제에 대한 이유 등을 학습하는 것 처럼 머신러닝도 Batch 크기만큼 데이터를 활용해 모델의 예측값
과 실제 값 간의 오차를 계산하여 파라미터를 업데이트한다.)
