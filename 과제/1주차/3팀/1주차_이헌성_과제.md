1. 티쳐블 머신 실습   
![스크린샷 2024-04-01 오후 7 01 50](https://github.com/sejongsmarcle/2024_Spring_SMARCLE_Snaegi_Study/assets/80825434/63637eb4-9970-4a60-a493-b5c8eb84b68d)
인공지능이 색을 주로 이용해서 사물을 구분할 것이라 생각하고 색이 비슷한 석류와 사과를 비교로 진행했습니다.
이때 사과의 데이터에는 초록색 사과에 대한 데이터를 추가하여 조금 더 분석의 정확도를 높이고 대조할 수 있는 대조군을 추가하였습니다.
실행 결과 색이 비슷한 석류의 경우에도 98프로의 확률로 정답을 맞추는 것을 확인 할 수 있었습니다.

3. 용어 정리   

[ batch size의 의미 ]   
batch size란 정확히 무엇을 의미할까요?   
전체 트레이닝 데이터 셋을 여러 작은 그룹을 나누었을 때 batch size는 하나의 소그룹에 속하는 데이터 수를 의미합니다.   
전체 트레이닝 셋을 작게 나누는 이유는 트레이닝 데이터를 통째로 신경망에 넣으면 비효율적이 리소스 사용으로 학습 시간이 오래 걸리기 때문입니다.   
   
 [ epoch의 의미 ]   
딥러닝에서 epoch는 전체 트레이닝 셋이 신경망을 통과한 횟수 의미합니다.    
예를 들어, 1-epoch는 전체 트레이닝 셋이 하나의 신경망에 적용되어 순전파와 역전파를 통해 신경망을 한 번 통과했다는 것을 의미합니다.   

[ iteration의 의미 ]   
iteration은 1-epoch를 마치는데 필요한 미니배치 갯수를 의미합니다.    
다른 말로, 1-epoch를 마치는데 필요한 파라미터 업데이트 횟수 이기도 합니다.    
각 미니 배치 마다 파라미터 업데이터가 한번씩 진행되므로 iteration은 파라미터 업데이트 횟수이자 미니배치 갯수입니다.    
예를 들어, 700개의 데이터를 100개씩 7개의 미니배치로 나누었을때, 1-epoch를 위해서는 7-iteration이 필요하며 7번의 파라미터 업데이트가 진행됩니다.   
